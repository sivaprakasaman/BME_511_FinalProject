\documentclass[9pt]{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{graphicx}
\usepackage{color}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{epstopdf}
\usepackage[table]{xcolor}
\usepackage[a4paper, total={6in, 10in}]{geometry}
\usepackage{enumitem}
\usepackage[export]{adjustbox}

\begin{document}
\begin{center}
{\Large \textbf{BME 0511 Final Project Proposal | Andrew Sivaprakasam}}
\end{center}

Despite extensive investigation of both perception and coding of Temporal Fine Structure (TFS) and Envelope (ENV) and how they play a role in speech intellibility and discrimination, there is a commonly presented stimulus whose coding still remains somewhat an enigma: \textit{music}. Though multiple studies have attempted to study music intelligibility and appreciation by creating music-music and music-noise chimaeras, the current work consists of studies that are primarily behavioral. Although these studies shed light on the roles of TFS and ENV in music encoding, their implications may be influenced by higher-level processing beyond the auditory periphery or by auditory filtering effects present in the cochlea. 

It is important to study how music is encoded independent of central processing and the relevance of auditory filtering effects in order to drive better design of hearing-assistive devices, such as cochlear implants. It has been well-established that cochlear implant users, despite developing substantial conversational proficiency, struggle to appreciate music through their implants [Citation]. To objectively study the encoding and filtering done by the auditory periphery, auditory nerve studies may be utilized.

Advances in modeling and characterization of TFS and ENV using spike-train analyses methods such as alternating-polarity Peristimulus Time Histograms (apPSTHs) may allow us to better understand music coding. 

 

\end{document}